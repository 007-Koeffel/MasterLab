---
title: "Final_Code_Group_7"
author: "Group_7"
date: "1/13/2022"
output:
  pdf_document: default
  html_document: default
---

```{r Environment Cleaning in order to start from scratch}
rm(list = ls()) #in order to have a free environment
```

Important to highlight is the _changing file paths_ in the data import section, which depends on the user. However, they can be easily changes by replacing the highlighted green path below:

First of all we create the necessary working space by downloading and installing the essential packages.
```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
#library(dplyr)
#library(tidyr)
#library(readr)
#library(readxl)
#library(tibbletime)
#library(zoo)
#library(lmtest)
#library(sandwich)
#library(RcppEigen)
#install.packages("slider")
#install.packages("beepr")
#install.packages("r2symbols")
#library(slider)
#library(beepr)
#library(r2symbols)
#installing and loading every needed package in order to have a prober functioning code
load("~/Library/Mobile Documents/com~apple~CloudDocs/Uni/Master/1. Semester/Empirical Methods/Paper Replication/and09-bali-et-al.-2017-5555947d52fe/Data/CRSP_monthly.RData") #used to import the monthly CRSP data set
load("~/Library/Mobile Documents/com~apple~CloudDocs/Uni/Master/1. Semester/Empirical Methods/Paper Replication/and09-bali-et-al.-2017-5555947d52fe/Data/CRSP_delist.RData") #used for importing the delisting data
```

__Data Loading__
After the procedure we proceed with the other data imports, the _CFNAI index_, the _uncertainty factor_, the _Mkt;HML; risk-free_. Furthermore, we proceed with the Momentum Factors from Fama French. Additionally, we obtain the liquidity factors, Hou_Xue_Zhang_monthly_factors.

```{r Data Loading}
CFNAI <- read_csv("/Users/fabian/Library/Mobile Documents/com~apple~CloudDocs/Uni/Master/1. Semester/Empirical Methods/Paper Replication/and09-bali-et-al.-2017-5555947d52fe/Data/CFNAI.CSV") %>% filter(date>"1967-12-29") %>% filter(date<"2019-01-01") %>% arrange(date) #CFNAI Index

Macro_Uncertainty <- read_xlsx("/Users/fabian/Library/Mobile Documents/com~apple~CloudDocs/Uni/Master/1. Semester/Empirical Methods/Paper Replication/and09-bali-et-al.-2017-5555947d52fe/Data/MacroUncertaintyToCirculate.XLSX") %>%
  mutate(date=as.Date(Date)) %>% filter(date>"1967-12-29",date<"2019-01-01") %>% rename(UNC="h=1") %>%
  arrange(Date) %>% select(date,UNC)

FF3 <- read_csv("/Users/fabian/Library/Mobile Documents/com~apple~CloudDocs/Uni/Master/1. Semester/Empirical Methods/Paper Replication/and09-bali-et-al.-2017-5555947d52fe/Data/FF_monthly_factors.CSV") %>% mutate(date=as.Date(as.yearmon(as.Date(paste0(date,"01"),format="%Y%m%d")+31))) %>%
  rename(Mkt.RF=`Mkt-RF`) %>% mutate(across(Mkt.RF:RF,~./100))

Momentum <- read_csv("/Users/fabian/Library/Mobile Documents/com~apple~CloudDocs/Uni/Master/1. Semester/Empirical Methods/Paper Replication/and09-bali-et-al.-2017-5555947d52fe/Data/FF_Momentum_Factor.CSV") %>% mutate(date=as.Date(as.yearmon(as.Date(paste0(date,"01"),format="%Y%m%d")+31))) %>%
  mutate(across(Mom,~./100))

Liquidity <- read_csv("/Users/fabian/Library/Mobile Documents/com~apple~CloudDocs/Uni/Master/1. Semester/Empirical Methods/Paper Replication/and09-bali-et-al.-2017-5555947d52fe/Data/Pastor_liquidity_factor.CSV") %>% mutate(date=as.Date(as.yearmon(as.Date(paste0(date,"01"),format="%Y%m%d")+31))) %>%
  select(date,LIQ) %>% mutate(LIQ=ifelse(LIQ==-99,NA,LIQ))

H_Factors <- read_csv("/Users/fabian/Library/Mobile Documents/com~apple~CloudDocs/Uni/Master/1. Semester/Empirical Methods/Paper Replication/and09-bali-et-al.-2017-5555947d52fe/Data/Hou_Xue_Zhang_monthly_factors.CSV") %>% mutate(date=as.Date(as.yearmon(as.Date(paste0(year*100+month,"01"),format="%Y%m%d")+31))) %>%
  select(date,R_ME,R_IA,R_ROE) %>% rename(SMB=R_ME) %>% mutate(across(SMB:R_ROE,~./100))
```

After the import of all the necessary data we put everything in one dataframe in order to proceed with the paper replication.

```{r Putting all the Factors and index into one data frame}
FACTORS <- CFNAI %>% left_join(Macro_Uncertainty,by="date") %>% left_join(FF3 %>% select(-SMB),by="date") %>% left_join(Momentum,by="date") %>%
  left_join(Liquidity,by="date") %>% left_join(H_Factors,by="date")
```

In order to perform the required steps for uncertainty betas estimation we need to clean our data. Especially, we need to ease the suviorship bias by applying the _delisting returns_ from the _crsp.delist_ dataframe. In order to avoid the survivorship bias, we adapt our data with the delisting returns. Specifically, when a stock is delisted we use the delisting reutn form the CRSP, if available. Otherwise, we assume the delisting return is -100%, unless the reason for delisting is coded as 500 (reason unavailable), 520 (went over the counter), 551-573, 580 (various reasons), 574 (bankruptcy) or 584 (does not meet exchange financial guidelines). For these observations, we assume that the delisting return is -30%.

```{r Data preperation and merging avoiding survivorship bias}
Data_Crsp_monthly <- crsp.monthly %>% as_tibble() %>%
  filter(!is.na(altprc)) %>% #filtering out NAs in the data base
  ungroup() %>% mutate(datem=as.yearmon(date)) %>%
  left_join(crsp.delist %>% as_tibble() %>% rename(date=dlstdt) %>% #joining the delisting together with the monthly crsp.monthly data set 
              arrange(permno,date) %>%
              mutate(datem=as.yearmon(date)) %>% select(-date) %>%
              group_by(permno,datem) %>%
              slice(n()) %>% # take the last value of each month (the one that counts for the return at EOM)
              distinct(),by=c("datem","permno")) %>% #add stock info
  arrange(permno,date) %>%
  #filter(!is.na(shrcd)) %>% filter stocks that are not having shrcd 10/11 
  mutate(ret_adj = case_when(is.na(dlstcd) ~ ret,
                             dlstcd==100 ~ ret, #is used in order to filter the necessary delisting codes
                             !is.na(dlstcd) & !is.na(dlret) ~ dlret,
                             dlstcd %in% c(500, 520, 580, 584) | #filtering the specific stocks with a -30% return
                               (dlstcd >= 551 & dlstcd <= 574) ~ -0.3,
                             TRUE ~ -1)) %>% #calculate adjusted returns (for delisting)
  group_by(permno,date) %>% slice(1) %>% # force to have unique permno-date combinations
  ungroup() %>%
  mutate(mktcap = abs(shrout * altprc) / 1000, # in millions of dollars, following Bali et al. 
         mktcap = if_else(mktcap == 0, as.numeric(NA), mktcap)) %>%
  select(date,permno,permco,shrout,prc,altprc,ret,ret_adj,mktcap) #selecting the needed data
```

Afterwards we apply a regression in order to determine the uncertainty betas. Therefore we also adopt to the data range from the paper by beginning starting our sample in _1972-07-31_ to _2014-12-31_. Afterward we also compute the excess return of the stocks. We also add the above imported Factors in order to use them in the following sections for determining the alphas.

```{r Regressions for determining the uncertainty betas}
data_clean <- Data_Crsp_monthly %>% filter(date>="1972-07-31",date<="2014-12-31") %>% #filtering the data range
  mutate(datem=as.yearmon(date)) %>% 
  left_join(FACTORS %>% mutate(datem=as.yearmon(date-1)) %>%  select(-date),by="datem") %>% #bringing the monthly observation together with the factors
  select(date,permno,altprc,ret,ret_adj,mktcap,CFNAI:R_ROE) %>% #selecting the necessary columns
  mutate(ret_adj_exc=ret_adj-RF) #In order to obtain the excess return
```

The following section is used for defining a regression function in order to test later the stock exposure to economic uncertainty. Furthermore we use the adjusted excess return.

```{r Defining the regression function}
data <- data_clean %>% filter(permno==10001,date>="1986-02-28",date<="1991-01-31") #only a sample in order to test get a feeling of the data

lmUNC <- function(data){ #In order to obtain the uncertainty betas
  if (mean(abs(data$altprc))<=5 | mean(abs(data$altprc))>=1000) {unc <- NA #if a stock is traded on average below 5 or over 1000 US-Dollar we reject them from our data set. Here is also a small divergence within the Bali due to the lacking information from the paper if it would be necessary for filering on an average base or on single events. We decided for an average base
  } else if (sum(is.na(data$ret_adj_exc))>24) {unc<-NA
  } else {
    unc <- fastLmPure(cbind(1,data$UNC,data$Mkt.RF,data$SMB,data$HML,data$Mom,data$LIQ,data$R_IA,data$R_ROE),data$ret_adj_exc)$coefficients[2]
  }
  return(unc)
}
```

Within the next section we perform a rolling regression, which uses the first 60 observation for each stock in order to estimate the uncertainty betas. We also rearrange the data set in _data_clean_beta_.

```{r Rolling regression and beta cleaning}
lmUNC(data) #sampling the in order to see how it works before attack
lm(ret_adj_exc ~ UNC + Mkt.RF+SMB+HML+Mom+LIQ+R_IA+R_ROE,data = data) #performing the rolling regression in order to evaluate the stock exposure to the uncertainty index
 test <- data_clean %>% filter(permno<=10010) %>% group_by(permno) %>%
   mutate(beta_unc=slide_dbl(.x = cur_data(), .f = ~lmUNC(.), .before = 60, .after = -1, .complete = TRUE))#before 60 used as an estimation point
 test %>% filter(permno==10001, date>="1991-01-31")
data %>% mutate(beta_unc=slide_dbl(.x = cur_data(), .f = ~lmUNC(data=.x), .before = 60, .after = -1, .complete = TRUE))
data_clean_beta <- data_clean %>% group_by(permno) %>%
  mutate(beta_unc=slide_dbl(.x = cur_data(), .f = ~lmUNC(.), .before = 60, .after = -1, .complete = TRUE))
```

Below we split the betas into deciles in order to form _ten portfolios_. These portfolios are formed by sorting the stock according to their uncertainty betas. Therefore, we obtain ten different portfolios.Furthermore we calculate the Equal-weighted and value-weighted return minus the risk free rate in order to obtain the excess return of those portfolios.

```{r Uncertainty Beta and Portfolio Construction}
data.pf <- data_clean_beta %>% mutate(lmktcap= dplyr::lag(mktcap)) %>% ungroup() %>% filter(!is.na(beta_unc), !is.na(lmktcap), !is.na(ret_adj_exc)) %>%
  group_by(date) %>% mutate(beta_unc_dec = ntile(beta_unc, 10 )) %>% ungroup()
data.pf %>% group_by(beta_unc_dec) %>% summarise(beta_unc)
pf <- data.pf %>% group_by(date, beta_unc_dec) %>% summarise(ret_ew = mean(ret_adj_exc), ret_vw=weighted.mean(ret_adj_exc, w = lmktcap))
ts_pf <- pf %>% group_by(beta_unc_dec) %>% summarise(across(contains("ret"),~mean(.)*100)) #equally returns and value-weighted returns
uncertainty_betas <- data.pf %>% group_by(beta_unc_dec) %>% summarise(across(contains("beta_unc"),~mean(.))) #Uncertainty Portfolios
```

The next chunk showcase the data preperation for the later followed alpha calculations. Therefore we filter the data set accodring to their factors _date_, _ret_ew_, _ret_vw_, _'Mkt.RF'_, _HML_, _Mom_, _LIQ_, _SMB_, _R_IA_, _R_ROE_, _beta_unc_dec_. 

```{r Portfolio Construction}
data_final_beta <- inner_join(data_clean_beta, data.pf, by=c("date", "permno")) %>% drop_na() %>% ungroup() %>% group_by(date) %>% arrange(date, permno) %>% mutate(beta_unc_dec = ntile(beta_unc.y,10)) %>% ungroup() %>% group_by(date, beta_unc_dec) %>% arrange(date, beta_unc_dec, permno) %>% mutate(EW=1/n(), VW=mktcap.x/sum(mktcap.x)) %>% mutate(EW_EXRET = EW*ret_adj_exc.x, VW_EXRET=VW*ret_adj_exc.x)
portfolios <- data_final_beta %>% mutate(EW_PORT_EXRET = sum(EW_EXRET), VW_PORT_EXRET=sum(VW_EXRET)) %>% ungroup() %>% group_by(beta_unc_dec,date) %>% mutate(UNC_BETA_AVG = mean(EW_PORT_EXRET), VW_PORT_EXRET_AVG=mean(VW_PORT_EXRET))
t <- "Thank you for the exciting course - Group 7" #Uncertainty Factor we only make use of the monthly uncertainty index
```

The next step is to compute the four different alphas for the _equally weighted_ portfolios and also the four alphas for the value weighted portfolios. Furthermore, we also examined t-tests in order to test for the significance niveau.
In the following sections we calculate the alphas for the equally-weighted portfolios and followed by that also the value-weighted portfolios.

```{r Equally-Weighted Alpha Computations}
alpha_5_1_EW <- vector()
t_value_5_1_EW <- vector()
for (i in 1:10){
  regression <- lm(EW_EXRET ~ Mkt.RF.x + SMB.x + HML.x + Mom.x + LIQ.x, #computing the alphas by using the above imported Factors
                   data = portfolios %>% distinct(date, .keep_all = T) %>% filter(beta_unc_dec == i))
  t_statistic <- coeftest(regression, vcov= NeweyWest(regression, verbose = T))
  alpha_5_1_EW[i] <- regression$coefficients[1]
  t_value_5_1_EW[i] <- t_statistic[1,3]
}
alpha_5_1_EW
t_value_5_1_EW

alpha_5_2_EW <- vector()
t_value_5_2_EW <- vector()
for (i in 1:10){
  regression <- lm(EW_EXRET ~ Mkt.RF.x + SMB.x + HML.x + R_IA.x + R_ROE.x,
                   data = portfolios %>% distinct(date, .keep_all = T) %>% filter(beta_unc_dec ==i))
  t_statistic <- coeftest(regression, vcov= NeweyWest(regression, verbose = T))
  alpha_5_2_EW[i] <- regression$coefficients[1]
  t_value_5_2_EW[i] <- t_statistic[1,3]
}
alpha_5_2_EW
t_value_5_2_EW

alpha_4_EW <- vector()
t_value_4_EW <- vector()
for (i in 1:10){
  regression <- lm(EW_EXRET ~ Mkt.RF.x + SMB.x + R_IA.x + R_ROE.x,
                   data = portfolios %>% distinct(date, .keep_all = T) %>% filter(beta_unc_dec ==i))
  t_statistic <- coeftest(regression, vcov= NeweyWest(regression, verbose = T))
  alpha_4_EW[i] <- regression$coefficients[1]
  t_value_4_EW[i] <- t_statistic[1,3]
}
alpha_4_EW
t_value_4_EW

alpha_7_EW <- vector()
t_value_7_EW <- vector()
for (i in 1:10){
  regression <- lm(EW_EXRET ~ Mkt.RF.x + SMB.x + R_IA.x + R_ROE.x,
                   data = portfolios %>% distinct(date, .keep_all = T) %>% filter(beta_unc_dec ==i))
  t_statistic <- coeftest(regression, vcov= NeweyWest(regression, verbose = T))
  alpha_7_EW[i] <- regression$coefficients[1]
  t_value_7_EW[i] <- t_statistic[1,3]
}
alpha_7_EW
t_value_7_EW
```

The same procedure as above is also now applied to the _value-weighted_ aplpha computations. Therefore, in order to highlight the differences to above performed code, we only switch the _EW_EXRET_ witht the _VW_EXRET_ variable in order to compute the alphas for the value-weighted portfolios.

```{r Value-Weighted Alpha Computations}
alpha_5_1_VW <- vector()
t_value_5_1_VW <- vector()
for (i in 1:10){
  regression <- lm(VW_EXRET ~ Mkt.RF.x + SMB.x + HML.x + Mom.x + LIQ.x,
                   data = portfolios %>% distinct(date, .keep_all = T) %>% filter(beta_unc_dec == i))
  t_statistic <- coeftest(regression, vcov= NeweyWest(regression, verbose = T))
  alpha_5_1_VW[i] <- regression$coefficients[1]
  t_value_5_1_VW[i] <- t_statistic[1,3]
}
alpha_5_1_VW
t_value_5_1_VW

alpha_5_2_VW <- vector()
t_value_5_2_VW <- vector()
for (i in 1:10){
  regression <- lm(VW_EXRET ~ Mkt.RF.x + SMB.x + HML.x + R_IA.x + R_ROE.x,
                   data = portfolios %>% distinct(date, .keep_all = T) %>% filter(beta_unc_dec ==i))
  t_statistic <- coeftest(regression, vcov= NeweyWest(regression, verbose = T))
  alpha_5_2_VW[i] <- regression$coefficients[1]
  t_value_5_2_VW[i] <- t_statistic[1,3]
}
alpha_5_2_VW
t_value_5_2_VW

alpha_4_VW <- vector()
t_value_4_VW <- vector()
for (i in 1:10){
  regression <- lm(VW_EXRET ~ Mkt.RF.x + SMB.x + R_IA.x + R_ROE.x,
                   data = portfolios %>% distinct(date, .keep_all = T) %>% filter(beta_unc_dec ==i))
  t_statistic <- coeftest(regression, vcov= NeweyWest(regression, verbose = T))
  alpha_4_VW[i] <- regression$coefficients[1]
  t_value_4_VW[i] <- t_statistic[1,3]
}
alpha_4_VW
t_value_4_VW

alpha_7_VW <- vector()
t_value_7_VW <- vector()
for (i in 1:10){
  regression <- lm(VW_EXRET ~ Mkt.RF.x + SMB.x + R_IA.x + R_ROE.x,
                   data = portfolios %>% distinct(date, .keep_all = T) %>% filter(beta_unc_dec ==i))
  t_statistic <- coeftest(regression, vcov= NeweyWest(regression, verbose = T))
  alpha_7_VW[i] <- regression$coefficients[1]
  t_value_7_VW[i] <- t_statistic[1,3]
}
alpha_7_VW
t_value_7_VW
```

Final steps in order to bring everything together in order to present our finiding in the _Final_Table_.

```{r}
ew_overview <- cbind(alpha_5_1_EW,t_value_5_1_EW, alpha_5_2_EW, t_value_5_2_EW, alpha_4_EW, t_value_4_EW, alpha_7_EW, t_value_7_EW)
vw_overview <- cbind(alpha_5_1_VW,t_value_5_1_VW, alpha_5_2_VW, t_value_5_2_VW, alpha_4_VW, t_value_4_VW, alpha_7_VW, t_value_7_VW)
final_table <- cbind(ts_pf$beta_unc_dec, uncertainty_betas$beta_unc, ts_pf$ret_ew, ew_overview, ts_pf$ret_vw, vw_overview)
final_table <- as.data.frame(final_table) 
hl_low_EW_alpha <- t(as.data.frame(ew_overview[1,]-ew_overview[10,]))
hl_low_VW_alpha_02 <- t(as.data.frame(vw_overview[1,]-vw_overview[10,]))
hl_lo_EW_RET <- as.data.frame(ts_pf[10,2]-ts_pf[1,2])
hl_lo_VW_RET <- as.data.frame(ts_pf[10,3]-ts_pf[1,3])
text <- t(c("High-","Low"))
last_row <- cbind(text,hl_lo_EW_RET,hl_low_EW_alpha, hl_lo_VW_RET, hl_low_VW_alpha_02)
final_table <- final_table %>% rename(DECILE = V1) %>% rename("RET-RF_EW" = V3) %>% rename("RET-RF_VW" = V12) %>% rename("Beta_UNC"= V2)
last_row <- last_row %>% rename(DECILE =1) %>% rename("RET-RF_EW" = ret_ew) %>% rename("RET-RF_VW" = ret_vw) %>% rename("Beta_UNC"= 2)
final_table <- rbind(final_table, last_row)
final_table
beepr::beep()
print(t)
```











